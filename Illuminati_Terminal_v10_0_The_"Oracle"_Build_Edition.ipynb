{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1UsMqIrvICCnGlYTyq6W2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitjha67/Illuminati-Terminal-v10.0---The-Oracle-Build-Edition/blob/main/Illuminati_Terminal_v10_0_The_%22Oracle%22_Build_Edition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33IL9g13Xd3G",
        "outputId": "76915468-c8f9-497b-ce31-9ffd0d8ea663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.12/dist-packages (6.0.12)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (3.13.2)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.12/dist-packages (3.2.9)\n",
            "Requirement already satisfied: trafilatura in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (3.14.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (3.1.6)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nselib in /usr/local/lib/python3.12/dist-packages (1.9)\n",
            "Collecting pandas_market_calendars\n",
            "  Using cached pandas_market_calendars-5.1.3-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp) (1.22.0)\n",
            "Requirement already satisfied: courlan>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.3.2)\n",
            "Requirement already satisfied: htmldate>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (1.9.4)\n",
            "Requirement already satisfied: justext>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.0.2)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (6.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from nselib) (1.16.3)\n",
            "Collecting exchange-calendars>=3.3 (from pandas_market_calendars)\n",
            "  Downloading exchange_calendars-4.11.3-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
            "Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Collecting pyluach>=2.3.0 (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading pyluach-2.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting toolz>=1.0.0 (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting korean_lunar_calendar>=0.3.1 (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading pandas_market_calendars-5.1.3-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.11.3-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: korean_lunar_calendar, toolz, pyluach, exchange-calendars, pandas_market_calendars\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.12.1\n",
            "    Uninstalling toolz-0.12.1:\n",
            "      Successfully uninstalled toolz-0.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed exchange-calendars-4.11.3 korean_lunar_calendar-0.3.1 pandas_market_calendars-5.1.3 pyluach-2.3.0 toolz-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install nest_asyncio yfinance pandas numpy requests feedparser tabulate reportlab nltk transformers schedule google-generativeai aiohttp xlsxwriter trafilatura rapidfuzz beautifulsoup4 ta jinja2 textblob nselib pandas_market_calendars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Illuminati Terminal v10.0 - The \"Oracle\" Build\n",
        "CONSOLIDATES & UPGRADES:\n",
        "- New: \"Trend Hunter\" (Predicts Booming Industries from News)\n",
        "- New: \"Full Deep Dive\" (Math breakdown for ALL stocks saved to file)\n",
        "- Fixed: Date/Time display uses system time.\n",
        "- Retains: Self-Healing, Waterfall Data, Moneycontrol Fix, Bearish Logic.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "import ssl\n",
        "import random\n",
        "import uuid\n",
        "import sqlite3\n",
        "import argparse\n",
        "import schedule\n",
        "import asyncio\n",
        "import logging\n",
        "import hashlib\n",
        "import datetime as dt\n",
        "from zoneinfo import ZoneInfo\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, quote_plus\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# --- 1. SELF-HEALING INSTALLER ---\n",
        "def install_dependencies():\n",
        "    required = [\n",
        "        'nselib', 'yfinance', 'pandas', 'numpy', 'requests', 'feedparser',\n",
        "        'tabulate', 'reportlab', 'nltk', 'transformers', 'schedule',\n",
        "        'google-generativeai', 'aiohttp', 'xlsxwriter', 'trafilatura',\n",
        "        'rapidfuzz', 'beautifulsoup4', 'ta', 'jinja2', 'textblob', 'nest_asyncio'\n",
        "    ]\n",
        "    installed = {pkg.split('==')[0] for pkg in sys.modules}\n",
        "    missing = [pkg for pkg in required if pkg not in installed]\n",
        "\n",
        "    if missing:\n",
        "        print(f\"ğŸ› ï¸ Installing missing modules: {', '.join(missing)}...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + missing,\n",
        "                                  stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"âœ… Dependencies installed. Starting System...\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Install failed: {e}\")\n",
        "\n",
        "try: import nselib\n",
        "except ImportError: install_dependencies()\n",
        "\n",
        "# --- 2. IMPORTS ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import aiohttp\n",
        "import feedparser\n",
        "import requests\n",
        "import nest_asyncio\n",
        "from requests.adapters import HTTPAdapter, Retry\n",
        "from tabulate import tabulate\n",
        "from textblob import TextBlob\n",
        "from bs4 import BeautifulSoup\n",
        "from jinja2 import Template\n",
        "from dateutil import parser as dateparser\n",
        "\n",
        "try: from nselib import capital_market; HAS_NSELIB = True\n",
        "except ImportError: HAS_NSELIB = False\n",
        "\n",
        "try: from ta.trend import SMAIndicator, MACD; from ta.momentum import RSIIndicator; HAS_TA = True\n",
        "except ImportError: HAS_TA = False\n",
        "\n",
        "try: import trafilatura; logging.getLogger('trafilatura').setLevel(logging.CRITICAL); HAS_TRAFILATURA = True\n",
        "except ImportError: HAS_TRAFILATURA = False\n",
        "\n",
        "try: import google.generativeai as genai; HAS_GEMINI = True\n",
        "except ImportError: HAS_GEMINI = False\n",
        "\n",
        "try: from transformers import pipeline as hf_pipeline; HAS_HF = True\n",
        "except ImportError: HAS_HF = False\n",
        "\n",
        "# --- 3. CONFIGURATION ---\n",
        "nest_asyncio.apply()\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
        "log = logging.getLogger(\"Illuminati\")\n",
        "\n",
        "DB_PATH = \"market_memory.db\"\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "CACHE_DIR = Path(\"cache\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "if hasattr(ssl, '_create_unverified_context'):\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "STOPLIST = set([\n",
        "    \"THE\", \"AND\", \"ARE\", \"IS\", \"FOR\", \"OVER\", \"WITH\", \"TO\", \"OF\", \"IN\",\n",
        "    \"BY\", \"FROM\", \"ON\", \"AT\", \"OR\", \"AS\", \"AN\", \"IT\", \"GO\", \"NO\",\n",
        "    \"MARKET\", \"COMPANY\", \"COMPANIES\", \"NEWS\", \"STOCK\", \"STOCKS\", \"SEBI\",\n",
        "    \"INDIAN\", \"INDIA\", \"EXPECTED\", \"LOSSES\", \"GAINS\", \"SHARES\", \"NSE\", \"BSE\",\n",
        "    \"DECLINE\", \"DECLINED\", \"ALSO\", \"FIRMS\", \"MONTHS\", \"SEGMENTS\", \"LTD\",\n",
        "    \"PRIMARY\", \"BOTH\", \"COMING\", \"FUNDRAISING\", \"SIGNIFICANT\", \"LIMITED\",\n",
        "    \"POSSIBLE\", \"HEALTH\", \"HEALTHCARE\", \"WAVE\", \"FIFTEEN\", \"EYE\", \"BANK\",\n",
        "    \"IPO\", \"IPOS\", \"SET\", \"RS\", \"BE\", \"WAS\", \"PUSH\", \"PARTICULARLY\", \"MUTUAL\", \"FUNDS\",\n",
        "    \"PRIVATE\", \"PUBLIC\", \"LOWER\", \"HIGHER\", \"TODAY\", \"WEEK\", \"YEAR\", \"REPORT\",\n",
        "    \"GLOBAL\", \"WORLD\", \"BUSINESS\", \"FINANCE\", \"MONEY\", \"TIMES\", \"ECONOMIC\", \"CITY\",\n",
        "    \"SALES\", \"PROFIT\", \"LOSS\", \"QUARTER\", \"RESULTS\", \"DATA\", \"GROUP\", \"IND\", \"OUT\"\n",
        "])\n",
        "\n",
        "SECTOR_MAP = {\n",
        "    'Technology': {'wacc': 0.13, 'growth': 0.12},\n",
        "    'Financial Services': {'wacc': 0.14, 'growth': 0.10},\n",
        "    'Energy': {'wacc': 0.11, 'growth': 0.05},\n",
        "    'Utilities': {'wacc': 0.10, 'growth': 0.04},\n",
        "    'Consumer Cyclical': {'wacc': 0.12, 'growth': 0.08},\n",
        "    'Healthcare': {'wacc': 0.11, 'growth': 0.09},\n",
        "    'Defense': {'wacc': 0.12, 'growth': 0.15}, # Added for Boom Prediction\n",
        "    'default': {'wacc': 0.12, 'growth': 0.08}\n",
        "}\n",
        "\n",
        "# Future Themes Dictionary\n",
        "FUTURE_THEMES = {\n",
        "    \"Green Energy\": [\"green hydrogen\", \"renewable\", \"solar\", \"wind\", \"ethanol\", \"clean energy\"],\n",
        "    \"Defense\": [\"defense\", \"drone\", \"missile\", \"weapon\", \"army\", \"navy\", \"air force\"],\n",
        "    \"EV & Auto\": [\"electric vehicle\", \"ev\", \"battery\", \"lithium\", \"charging\"],\n",
        "    \"AI & Tech\": [\"artificial intelligence\", \"ai\", \"semiconductor\", \"chip\", \"data center\", \"cloud\"],\n",
        "    \"Infrastructure\": [\"highway\", \"road\", \"metro\", \"railway\", \"infra\", \"construction\"],\n",
        "    \"Banking\": [\"credit\", \"loan\", \"npa\", \"rbi\", \"bank\", \"finance\"]\n",
        "}\n",
        "\n",
        "DEFAULT_FEEDS = [\n",
        "    \"https://news.google.com/rss/search?q=site:moneycontrol.com+when:7d&hl=en-IN&gl=IN&ceid=IN:en\",\n",
        "    \"https://economictimes.indiatimes.com/markets/rssfeeds/1977021501.cms\",\n",
        "    \"https://economictimes.indiatimes.com/markets/stocks/rssfeeds/2146842.cms\",\n",
        "    \"https://www.livemint.com/rss/markets\",\n",
        "    \"https://www.business-standard.com/rss/markets-106.rss\",\n",
        "    \"https://www.financialexpress.com/market/feed/\",\n",
        "    \"https://feeds.reuters.com/reuters/INbusinessNews\",\n",
        "    \"https://feeds.bloomberg.com/markets/news.rss\"\n",
        "]\n",
        "\n",
        "# ==========================================\n",
        "# 4. MARKET MAPPER & TREND HUNTER\n",
        "# ==========================================\n",
        "class MasterMapper:\n",
        "    def __init__(self):\n",
        "        self.universe = {}\n",
        "        self.keywords = {}\n",
        "        self.build_universe()\n",
        "\n",
        "    def build_universe(self):\n",
        "        log.info(\"â³ Indexing NSE Market (nselib)...\")\n",
        "        try:\n",
        "            if HAS_NSELIB:\n",
        "                df = capital_market.equity_list()\n",
        "                for index, row in df.iterrows():\n",
        "                    symbol = row['SYMBOL']\n",
        "                    name = str(row['NAME OF COMPANY']).upper()\n",
        "                    self.universe[symbol] = symbol\n",
        "                    self.universe[name] = symbol\n",
        "                    simple = name.replace(\"LIMITED\", \"\").replace(\"LTD\", \"\").strip()\n",
        "                    self.universe[simple] = symbol\n",
        "                    first = simple.split()[0]\n",
        "                    if len(first) > 3 and first not in STOPLIST:\n",
        "                        self.keywords[first] = symbol\n",
        "                log.info(f\"âœ… Indexed {len(self.universe)} companies.\")\n",
        "            else: raise Exception(\"nselib not found\")\n",
        "        except Exception as e:\n",
        "            log.warning(f\"âš ï¸ NSE Indexing failed. Using Fallback.\")\n",
        "            defaults = ['RELIANCE', 'TCS', 'INFY', 'HDFCBANK', 'ICICIBANK', 'SBIN', 'TATAMOTORS', 'ITC', 'BAJFINANCE', 'LT', 'MARUTI']\n",
        "            for d in defaults: self.universe[d] = d\n",
        "\n",
        "    def extract_tickers(self, articles):\n",
        "        found = []\n",
        "        for art in articles:\n",
        "            text = f\"{art['title']} {art.get('body', '')[:500]}\".upper()\n",
        "            matches = re.findall(r'\\b([A-Z]{3,})\\b', text)\n",
        "            for m in matches:\n",
        "                if m in self.universe: found.append(self.universe[m])\n",
        "                elif m in self.keywords: found.append(self.keywords[m])\n",
        "        return list(set(found))\n",
        "\n",
        "class TrendHunter:\n",
        "    def predict_booming_industries(self, articles):\n",
        "        log.info(\"ğŸ”® Predicting Future Booming Industries...\")\n",
        "        scores = {k: 0 for k in FUTURE_THEMES.keys()}\n",
        "\n",
        "        for art in articles:\n",
        "            text = (art['title'] + \" \" + art.get('body', '')).lower()\n",
        "            for theme, keywords in FUTURE_THEMES.items():\n",
        "                for kw in keywords:\n",
        "                    if kw in text:\n",
        "                        scores[theme] += 1\n",
        "\n",
        "        # Normalize\n",
        "        total_hits = sum(scores.values())\n",
        "        if total_hits == 0: return []\n",
        "\n",
        "        trends = []\n",
        "        for theme, score in scores.items():\n",
        "            strength = round((score / total_hits) * 100, 1)\n",
        "            trends.append({'Theme': theme, 'Hype_Score': strength, 'Mentions': score})\n",
        "\n",
        "        return sorted(trends, key=lambda x: x['Hype_Score'], reverse=True)\n",
        "\n",
        "# ==========================================\n",
        "# 5. UTILITIES\n",
        "# ==========================================\n",
        "class APIKeys:\n",
        "    def __init__(self):\n",
        "        self.keys = {}\n",
        "        for k in [\"TWELVEDATA\", \"FINNHUB\", \"ALPHAVANTAGE\", \"NEWSAPI\", \"GEMINI\"]:\n",
        "            val = os.environ.get(f\"{k}_KEY\") or os.environ.get(f\"{k}_API_KEY\")\n",
        "            if val: self.keys[k] = val\n",
        "    def get(self, name): return self.keys.get(name)\n",
        "    def interactive_load(self):\n",
        "        print(\"\\nğŸ” API Key Setup (Press Enter to skip):\")\n",
        "        for k in [\"TWELVEDATA\", \"FINNHUB\", \"ALPHAVANTAGE\", \"GEMINI\"]:\n",
        "            if k not in self.keys:\n",
        "                val = input(f\"   Enter {k} Key: \").strip()\n",
        "                if val: self.keys[k] = val\n",
        "\n",
        "class DiskCache:\n",
        "    def __init__(self, base_dir: Path, ttl_seconds: int = 21600):\n",
        "        self.base_dir = base_dir; self.ttl = ttl_seconds\n",
        "        (base_dir / \"pages\").mkdir(exist_ok=True)\n",
        "    def _key(self, url: str) -> str: return hashlib.sha1(url.encode(\"utf-8\")).hexdigest()\n",
        "    def get(self, url: str) -> Optional[str]:\n",
        "        path = self.base_dir / \"pages\" / f\"{self._key(url)}.txt\"\n",
        "        if path.exists() and (time.time() - path.stat().st_mtime) < self.ttl:\n",
        "            try: return path.read_text(encoding=\"utf-8\")\n",
        "            except: pass\n",
        "        return None\n",
        "    def set(self, url: str, content: str):\n",
        "        try: (self.base_dir / \"pages\" / f\"{self._key(url)}.txt\").write_text(content, encoding=\"utf-8\")\n",
        "        except: pass\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, db_path=DB_PATH):\n",
        "        if os.path.exists(db_path):\n",
        "            try: os.remove(db_path)\n",
        "            except: pass\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self.create_tables()\n",
        "    def create_tables(self):\n",
        "        c = self.conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS news_items (uid TEXT PRIMARY KEY, timestamp DATETIME, source TEXT, title TEXT, body TEXT, sentiment_score REAL, tickers TEXT)''')\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS asset_analysis (run_id TEXT, timestamp DATETIME, ticker TEXT, price REAL, target_price REAL, horizon TEXT, sharpe REAL, score REAL, verdict TEXT, trend TEXT, rsi REAL)''')\n",
        "        self.conn.commit()\n",
        "    def save_news(self, items):\n",
        "        c = self.conn.cursor()\n",
        "        for i in items:\n",
        "            try: c.execute(\"INSERT OR IGNORE INTO news_items VALUES (?,?,?,?,?,?,?)\", (i['uid'], i['published'], i['source'], i['title'], i.get('body', '')[:5000], i['score'], str(i['tickers'])))\n",
        "            except: pass\n",
        "        self.conn.commit()\n",
        "    def save_analysis(self, results):\n",
        "        c = self.conn.cursor()\n",
        "        run_id = str(uuid.uuid4())[:8]; ts = dt.datetime.now().isoformat()\n",
        "        for r in results:\n",
        "            c.execute(\"INSERT INTO asset_analysis VALUES (?,?,?,?,?,?,?,?,?,?,?)\", (run_id, ts, r['Ticker'], r['Price'], r.get('Target_Price',0), r.get('Horizon',''), r.get('Sharpe',0), r['Score'], r['Verdict'], r['Trend'], r['RSI']))\n",
        "        self.conn.commit()\n",
        "\n",
        "# ==========================================\n",
        "# 6. NEWS ENGINE\n",
        "# ==========================================\n",
        "class NewsEngine:\n",
        "    def __init__(self, api_keys: APIKeys):\n",
        "        self.keys = api_keys\n",
        "        self.cache = DiskCache(CACHE_DIR)\n",
        "        self.feeds = list(set(DEFAULT_FEEDS))\n",
        "        self.session_sync = requests.Session()\n",
        "        self.session_sync.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        self._setup_nlp()\n",
        "    def _setup_nlp(self):\n",
        "        try: nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "        except LookupError: nltk.download('vader_lexicon', quiet=True)\n",
        "        self.vader = SentimentIntensityAnalyzer()\n",
        "        self.finbert = None\n",
        "        if HAS_HF:\n",
        "            try: self.finbert = hf_pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\", tokenizer=\"ProsusAI/finbert\", truncation=True)\n",
        "            except: pass\n",
        "    def add_google_news_feed(self, query):\n",
        "        q = quote_plus(query)\n",
        "        self.feeds.append(f\"https://news.google.com/rss/search?q={q}&hl=en-IN&gl=IN&ceid=IN:en\")\n",
        "    def extract_body(self, url):\n",
        "        cached = self.cache.get(url)\n",
        "        if cached: return cached\n",
        "        try:\n",
        "            resp = self.session_sync.get(url, timeout=10)\n",
        "            if not resp.ok: return \"\"\n",
        "            text = trafilatura.extract(resp.text) if HAS_TRAFILATURA else \"\"\n",
        "            if not text:\n",
        "                soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "                text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "            if text: self.cache.set(url, text); return text[:3000]\n",
        "        except: pass\n",
        "        return \"\"\n",
        "    async def fetch_feed_async(self, session, url):\n",
        "        try:\n",
        "            async with session.get(url, timeout=15) as response:\n",
        "                if response.status == 200: return feedparser.parse(await response.read())\n",
        "        except: return None\n",
        "    async def collect_all(self):\n",
        "        log.info(f\"ğŸ“¡ Scanning {len(self.feeds)} feeds (incl Moneycontrol Proxy)...\")\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            tasks = [self.fetch_feed_async(session, url) for url in self.feeds]\n",
        "            results = await asyncio.gather(*tasks)\n",
        "        articles = []\n",
        "        cutoff = dt.datetime.now() - dt.timedelta(days=7)\n",
        "        for res in results:\n",
        "            if not res: continue\n",
        "            for entry in res.entries[:15]:\n",
        "                try:\n",
        "                    pub_date = None\n",
        "                    if 'published' in entry:\n",
        "                        try: pub_date = dateparser.parse(entry.published).replace(tzinfo=None)\n",
        "                        except: pass\n",
        "                    if pub_date and pub_date < cutoff: continue\n",
        "                    articles.append({\n",
        "                        'title': entry.title,\n",
        "                        'link': entry.link,\n",
        "                        'published': (pub_date or dt.datetime.now()).isoformat(),\n",
        "                        'source': urlparse(entry.link).netloc.replace('www.', ''),\n",
        "                        'uid': str(uuid.uuid5(uuid.NAMESPACE_URL, entry.link))\n",
        "                    })\n",
        "                except: pass\n",
        "        return articles\n",
        "    def score_text(self, text):\n",
        "        v_score = self.vader.polarity_scores(text)['compound']\n",
        "        f_score = 0\n",
        "        if self.finbert:\n",
        "            try:\n",
        "                res = self.finbert(text[:512])[0]; val = res['score']\n",
        "                f_score = -val if res['label'] == 'negative' else val\n",
        "            except: pass\n",
        "        return round((v_score * 0.4) + (f_score * 0.6) if f_score != 0 else v_score, 3)\n",
        "    def process(self):\n",
        "        loop = asyncio.get_event_loop()\n",
        "        articles = loop.run_until_complete(self.collect_all())\n",
        "        random.shuffle(articles) # MIXER\n",
        "        log.info(f\"ğŸ“¥ Extracting body text for {len(articles)} articles...\")\n",
        "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "            body_map = list(executor.map(lambda a: self.extract_body(a['link']), articles))\n",
        "        unique = []; seen = set()\n",
        "        for i, art in enumerate(articles):\n",
        "            if art['title'] not in seen:\n",
        "                art['body'] = body_map[i]\n",
        "                art['score'] = self.score_text(f\"{art['title']} {art['body'][:300]}\")\n",
        "                unique.append(art); seen.add(art['title'])\n",
        "        return unique\n",
        "\n",
        "# ==========================================\n",
        "# 7. ANALYSIS & STRATEGY\n",
        "# ==========================================\n",
        "class DataEngine:\n",
        "    def __init__(self, api_keys: APIKeys):\n",
        "        self.keys = api_keys\n",
        "        self.session = requests.Session()\n",
        "    def fetch_data(self, ticker, days=365):\n",
        "        plain_ticker = ticker.replace('.NS', '')\n",
        "        if self.keys.get(\"TWELVEDATA\"):\n",
        "            try:\n",
        "                url = f\"https://api.twelvedata.com/time_series?symbol={plain_ticker}&interval=1day&outputsize={days}&apikey={self.keys.get('TWELVEDATA')}\"\n",
        "                data = self.session.get(url).json()\n",
        "                if 'values' in data:\n",
        "                    df = pd.DataFrame(data['values']); df['close'] = pd.to_numeric(df['close']); df.index = pd.to_datetime(df['datetime'])\n",
        "                    return df['close'].sort_index(), {}, None, \"TwelveData\"\n",
        "            except: pass\n",
        "        try:\n",
        "            yf_ticker = f\"{ticker}.NS\" if not ticker.endswith('.NS') else ticker\n",
        "            stock = yf.Ticker(yf_ticker)\n",
        "            hist = stock.history(period=\"1y\")\n",
        "            if not hist.empty: return hist['Close'], stock.info, stock, \"Yahoo\"\n",
        "        except: pass\n",
        "        return None, None, None, \"None\"\n",
        "\n",
        "class AnalysisLab:\n",
        "    def calculate_technicals(self, prices):\n",
        "        if len(prices) < 55: return {}\n",
        "        df = pd.DataFrame({'close': prices})\n",
        "        df['SMA50'] = df['close'].rolling(50).mean()\n",
        "        df['SMA200'] = df['close'].rolling(200).mean()\n",
        "        exp12 = df['close'].ewm(span=12, adjust=False).mean()\n",
        "        exp26 = df['close'].ewm(span=26, adjust=False).mean()\n",
        "        df['MACD'] = exp12 - exp26\n",
        "        df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "        delta = df['close'].diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "        rs = gain / loss\n",
        "        df['RSI'] = 100 - (100 / (1 + rs))\n",
        "        curr = df.iloc[-1]\n",
        "        trend = \"SIDEWAYS\"\n",
        "        if curr['close'] > curr['SMA50'] > curr['SMA200']: trend = \"UPTREND\"\n",
        "        elif curr['close'] < curr['SMA50'] < curr['SMA200']: trend = \"DOWNTREND\"\n",
        "        return {\"RSI\": round(curr['RSI'], 1), \"Trend\": trend, \"MACD_Signal\": \"Bullish\" if curr['MACD'] > curr['Signal'] else \"Bearish\", \"Volatility\": round(prices.pct_change().std() * np.sqrt(252), 2)}\n",
        "\n",
        "    def calculate_valuation(self, stock, info, current_price):\n",
        "        try:\n",
        "            cashflow = stock.cashflow\n",
        "            if cashflow is not None and not cashflow.empty:\n",
        "                ocf = cashflow.iloc[0, 0]; capex = abs(cashflow.iloc[1, 0]); fcf = ocf - capex\n",
        "                sector = info.get('sector', 'default')\n",
        "                params = SECTOR_MAP.get(sector, SECTOR_MAP['default'])\n",
        "                growth, wacc, shares = params['growth'], params['wacc'], info.get('sharesOutstanding', 1)\n",
        "                future_val = 0\n",
        "                for i in range(1, 6): future_val += (fcf * ((1 + growth) ** i)) / ((1 + wacc) ** i)\n",
        "                term_val = (fcf * ((1 + growth)**5) * 1.04) / (wacc - 0.04)\n",
        "                intrinsic = (future_val + (term_val / ((1 + wacc) ** 5))) / shares\n",
        "                if intrinsic > 0 and intrinsic < current_price*5:\n",
        "                    return round(intrinsic, 2)\n",
        "        except: pass\n",
        "        try:\n",
        "            eps = info.get('trailingEps')\n",
        "            if eps and eps > 0: return round(eps * 20, 2)\n",
        "        except: pass\n",
        "        return \"N/A\"\n",
        "\n",
        "    def stress_test(self, price, sector):\n",
        "        shocks = {'Energy': 0.08, 'Financial Services': -0.05, 'Technology': -0.10, 'default': -0.03}\n",
        "        impact = shocks.get(sector, shocks['default'])\n",
        "        return round(price * (1 + impact), 2)\n",
        "\n",
        "    def determine_strategy(self, price, dcf_val, trend, score, volatility):\n",
        "        target_price = price; horizon = \"Watchlist\"\n",
        "        tech_upside = price * (1 + volatility)\n",
        "        if isinstance(dcf_val, (int, float)) and not np.isnan(dcf_val):\n",
        "            if dcf_val > price: target_price = (dcf_val * 0.6) + (tech_upside * 0.4)\n",
        "            else: target_price = (dcf_val * 0.3) + (price * 0.7)\n",
        "        else: target_price = price * 1.15 if trend == \"UPTREND\" else price * 0.95\n",
        "\n",
        "        if score >= 75: horizon = \"Long Term (1-3 Yrs)\"\n",
        "        elif score >= 60: horizon = \"Mid Term (3-6 Mos)\"\n",
        "        elif score <= 40: horizon = \"Exit / Short Term\"\n",
        "        else: horizon = \"Swing / Neutral\"\n",
        "        return round(target_price, 2), horizon\n",
        "\n",
        "    def compute_risk_metrics(self, prices):\n",
        "        if len(prices) < 30: return {}\n",
        "        ret = prices.pct_change().dropna()\n",
        "        rf = 0.07 / 252\n",
        "        mean, std = ret.mean(), ret.std()\n",
        "        sharpe = ((mean - rf) / std) * np.sqrt(252) if std > 0 else 0\n",
        "        cum = (1 + ret).cumprod()\n",
        "        max_dd = ((cum - cum.cummax()) / cum.cummax()).min()\n",
        "        return {\"Sharpe\": round(sharpe, 2), \"MaxDD\": round(max_dd, 3)}\n",
        "\n",
        "    def analyze_asset(self, ticker, prices, info, stock, source):\n",
        "        tech = self.calculate_technicals(prices)\n",
        "        if not tech: return None\n",
        "        val = self.calculate_valuation(stock, info, prices.iloc[-1])\n",
        "        risk = self.compute_risk_metrics(prices)\n",
        "        stress_px = self.stress_test(prices.iloc[-1], info.get('sector', 'default'))\n",
        "\n",
        "        score = 50\n",
        "        if tech['Trend'] == \"UPTREND\": score += 20\n",
        "        if tech['MACD_Signal'] == \"Bullish\": score += 10\n",
        "        if tech['RSI'] < 30: score += 15\n",
        "        elif tech['RSI'] > 70: score -= 15\n",
        "        if isinstance(val, (int, float)) and val > prices.iloc[-1]: score += 20\n",
        "        if risk.get('Sharpe', 0) > 1: score += 10\n",
        "\n",
        "        if tech['Trend'] == \"DOWNTREND\": score -= 20\n",
        "        if tech['RSI'] > 70: score -= 15\n",
        "        if isinstance(val, (int, float)) and val < prices.iloc[-1] * 0.8: score -= 10\n",
        "        if risk.get('Sharpe', 0) < 0: score -= 5\n",
        "\n",
        "        verdict = \"HOLD\"\n",
        "        if score >= 75: verdict = \"STRONG BUY\"\n",
        "        elif score >= 60: verdict = \"BUY\"\n",
        "        elif score <= 20: verdict = \"STRONG SELL\"\n",
        "        elif score <= 40: verdict = \"SELL\"\n",
        "\n",
        "        target, horizon = self.determine_strategy(prices.iloc[-1], val, tech['Trend'], score, tech['Volatility'])\n",
        "\n",
        "        dd_data = {\n",
        "            \"Score_Breakdown\": [f\"Final Score: {score}\", f\"Trend: {tech['Trend']}\", f\"Sharpe: {risk.get('Sharpe')}\"],\n",
        "            \"Valuation_Method\": \"DCF\" if isinstance(val, (int, float)) and val != 0 else \"Estimate\",\n",
        "            \"Stress_Test_Oil_Shock\": stress_px\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"Ticker\": ticker, \"Price\": round(prices.iloc[-1], 2), \"Target_Price\": target,\n",
        "            \"Horizon\": horizon, \"Trend\": tech['Trend'], \"RSI\": tech['RSI'],\n",
        "            \"DCF_Val\": val, \"Sharpe\": risk.get('Sharpe'), \"Score\": score,\n",
        "            \"Verdict\": verdict, \"Sector\": info.get('sector', 'Unknown'),\n",
        "            \"Deep_Dive_Data\": dd_data\n",
        "        }\n",
        "\n",
        "# ==========================================\n",
        "# 8. REPORTING & GENERATORS\n",
        "# ==========================================\n",
        "class ReportLab:\n",
        "    def __init__(self, out_dir): self.out_dir = out_dir\n",
        "    def generate_html_dashboard(self, results, articles, trends):\n",
        "        template = \"\"\"<!DOCTYPE html><html><head><title>Illuminati v10.0</title><style>body{font-family:'Inter',sans-serif;background:#0f172a;color:#e2e8f0;padding:20px}.card{background:#1e293b;border-radius:8px;padding:15px;margin-bottom:15px;border:1px solid #334155}.badge{padding:4px 8px;border-radius:4px;font-weight:bold}.buy{background:#065f46;color:#34d399}.sell{background:#7f1d1d;color:#f87171}.hold{background:#854d0e;color:#fef08a}table{width:100%;border-collapse:collapse;margin-top:20px}th,td{padding:12px;text-align:left;border-bottom:1px solid #334155}th{color:#94a3b8}</style></head><body><h1>ğŸ‘ï¸ Illuminati Terminal v10.0</h1><p>Assets Analyzed: {{ total }} | Date: {{ date }}</p><h2>ğŸ”® Future Booming Industries</h2><table><thead><tr><th>Theme</th><th>Hype Score</th><th>Mentions</th></tr></thead><tbody>{% for t in trends %}<tr><td><b>{{ t.Theme }}</b></td><td>{{ t.Hype_Score }}%</td><td>{{ t.Mentions }}</td></tr>{% endfor %}</tbody></table><h2>ğŸš€ Investment Strategy</h2><table><thead><tr><th>Ticker</th><th>Price</th><th>Target</th><th>Horizon</th><th>Sharpe</th><th>Valuation</th><th>Score</th><th>Verdict</th></tr></thead><tbody>{% for r in results %}<tr><td><b>{{ r.Ticker }}</b></td><td>{{ r.Price }}</td><td>{{ r.Target_Price }}</td><td>{{ r.Horizon }}</td><td>{{ r.Sharpe }}</td><td>{{ r.DCF_Val }}</td><td>{{ r.Score }}</td><td><span class=\"badge {{ 'buy' if 'BUY' in r.Verdict else ('sell' if 'SELL' in r.Verdict else 'hold') }}\">{{ r.Verdict }}</span></td></tr>{% endfor %}</tbody></table><h2>ğŸ“° Market Intel</h2>{% for a in articles[:8] %}<div class=\"card\"><h3><a href=\"{{ a.link }}\" style=\"color:#60a5fa\">{{ a.title }}</a></h3><p style=\"color:#94a3b8\">{{ a.published }} | {{ a.source }}</p><p>{{ a.body[:250] }}...</p></div>{% endfor %}</body></html>\"\"\"\n",
        "        try:\n",
        "            t = Template(template)\n",
        "            html = t.render(results=results, articles=articles, trends=trends, date=dt.datetime.now(), total=len(results))\n",
        "            with open(self.out_dir / f\"Dashboard_{dt.datetime.now().strftime('%H%M')}.html\", \"w\") as f: f.write(html)\n",
        "        except Exception as e: log.error(f\"HTML Error: {e}\")\n",
        "\n",
        "    def generate_full_deep_dive(self, results):\n",
        "        # NEW: Write ALL deep dives to text file\n",
        "        path = self.out_dir / f\"Deep_Dive_Full_{dt.datetime.now().strftime('%H%M')}.txt\"\n",
        "        with open(path, 'w') as f:\n",
        "            f.write(f\"ILLUMINATI DEEP DIVE REPORT | {dt.datetime.now()}\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "            for r in results:\n",
        "                f.write(f\"Ticker: {r['Ticker']} | Price: {r['Price']} | Verdict: {r['Verdict']}\\n\")\n",
        "                f.write(f\"Target: {r['Target_Price']} ({r['Horizon']})\\n\")\n",
        "                f.write(f\"Score Components: {r['Deep_Dive_Data']['Score_Breakdown']}\\n\")\n",
        "                f.write(f\"Valuation ({r['Deep_Dive_Data']['Valuation_Method']}): {r['DCF_Val']}\\n\")\n",
        "                f.write(f\"Oil Shock Price: {r['Deep_Dive_Data']['Stress_Test_Oil_Shock']}\\n\")\n",
        "                f.write(\"-\" * 30 + \"\\n\\n\")\n",
        "        return path\n",
        "\n",
        "class GeminiBrain:\n",
        "    def __init__(self, api_key=None):\n",
        "        self.active = False\n",
        "        if HAS_GEMINI and api_key:\n",
        "            genai.configure(api_key=api_key)\n",
        "            self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "            self.active = True\n",
        "    def generate_narrative(self, df_summary):\n",
        "        if not self.active: return \"LLM Analysis Disabled.\"\n",
        "        try: return self.model.generate_content(f\"Analyze this Indian Stock Market data:\\n{df_summary.to_csv()}\").text\n",
        "        except: return \"LLM Generation Failed.\"\n",
        "\n",
        "def print_deep_dive_console(asset):\n",
        "    if not asset: return\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"ğŸ”¬ DEEP DIVE HIGHLIGHT: {asset['Ticker']}\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Current Price: â‚¹{asset['Price']}  |  Target: â‚¹{asset['Target_Price']}\")\n",
        "    print(f\"Verdict: {asset['Verdict']}  |  Horizon: {asset['Horizon']}\")\n",
        "    print(f\"Valuation Method: {asset['Deep_Dive_Data']['Valuation_Method']}\")\n",
        "    print(f\"Calculated Fair Value: {asset['DCF_Val']}\")\n",
        "    print(f\"Score Factors: {asset['Deep_Dive_Data']['Score_Breakdown']}\")\n",
        "\n",
        "# ==========================================\n",
        "# 9. ORCHESTRATOR\n",
        "# ==========================================\n",
        "def run_illuminati(interactive=False, tickers_arg=None):\n",
        "    # FIXED DATE DISPLAY\n",
        "    current_time = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ğŸ‘ï¸ ILLUMINATI TERMINAL v10.0 (ORACLE) | {current_time}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    api = APIKeys()\n",
        "    if interactive: api.interactive_load()\n",
        "\n",
        "    db = DatabaseManager()\n",
        "    news = NewsEngine(api)\n",
        "    mapper = MasterMapper()\n",
        "    data = DataEngine(api)\n",
        "    lab = AnalysisLab()\n",
        "    trend_hunter = TrendHunter()\n",
        "    reporter = ReportLab(OUTPUT_DIR)\n",
        "    llm = GeminiBrain(api.get(\"GEMINI\"))\n",
        "\n",
        "    news.add_google_news_feed(\"Indian Stock Market News\")\n",
        "    articles = news.process()\n",
        "    db.save_news(articles)\n",
        "\n",
        "    # PREDICT BOOMING INDUSTRIES\n",
        "    trends = trend_hunter.predict_booming_industries(articles)\n",
        "    if trends:\n",
        "        print(\"\\nğŸ”® PREDICTED BOOMING INDUSTRIES (News Hype):\")\n",
        "        print(tabulate(pd.DataFrame(trends).head(5), headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "    tickers = mapper.extract_tickers(articles)\n",
        "    if tickers_arg: tickers.extend(tickers_arg.split(','))\n",
        "    tickers = list(set(tickers))\n",
        "\n",
        "    if not tickers:\n",
        "        log.warning(\"No tickers found. Using Default Watchlist.\")\n",
        "        tickers = ['RELIANCE', 'TCS', 'INFY', 'HDFCBANK', 'ICICIBANK', 'TATAMOTORS', 'BAJFINANCE']\n",
        "\n",
        "    print(f\"\\nâš¡ Analyzing {len(tickers)} Assets...\")\n",
        "    results = []\n",
        "\n",
        "    for t in tickers:\n",
        "        try:\n",
        "            prices, info, stock, src = data.fetch_data(t)\n",
        "            if prices is None: continue\n",
        "\n",
        "            res = lab.analyze_asset(t, prices, info, stock, src)\n",
        "            if res:\n",
        "                results.append(res)\n",
        "                target_str = f\"{res['Target_Price']:.2f}\" if isinstance(res['Target_Price'], (int, float)) else \"N/A\"\n",
        "                print(f\"   -> {t.ljust(12)} | Target: {target_str.ljust(10)} | {res['Horizon'].ljust(18)} | {res['Verdict']}\")\n",
        "        except Exception as e: log.error(f\"Error {t}: {e}\")\n",
        "\n",
        "    if results:\n",
        "        df = pd.DataFrame(results).sort_values(\"Score\", ascending=False)\n",
        "        db.save_analysis(results)\n",
        "\n",
        "        # Reports\n",
        "        reporter.generate_html_dashboard(results, articles, trends)\n",
        "        dd_path = reporter.generate_full_deep_dive(results)\n",
        "        ts = dt.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "        df.to_excel(OUTPUT_DIR / f\"Strategy_{ts}.xlsx\", index=False)\n",
        "\n",
        "        narrative = llm.generate_narrative(df.head(10))\n",
        "        print(f\"\\nğŸ¤– AI Insight: {narrative[:300]}...\\n\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ğŸ“Š STRATEGIC VERDICT\")\n",
        "        print(\"=\"*80)\n",
        "        print(tabulate(df[['Ticker', 'Price', 'Target_Price', 'Horizon', 'Sharpe', 'Verdict']].head(20), headers='keys', tablefmt='psql', showindex=False))\n",
        "\n",
        "        if not df.empty:\n",
        "            print_deep_dive_console(df.iloc[0].to_dict())\n",
        "\n",
        "        print(f\"\\nâœ… All Reports Saved to: {OUTPUT_DIR}\")\n",
        "        print(f\"ğŸ“„ Full Deep Dive Analysis saved to: {dd_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--interactive\", action=\"store_true\")\n",
        "    parser.add_argument(\"--tickers\", type=str)\n",
        "    args = parser.parse_args(args=[] if 'google.colab' in sys.modules else None)\n",
        "\n",
        "    is_interactive = args.interactive or (len(sys.argv) == 1 and 'google.colab' not in sys.modules)\n",
        "    run_illuminati(interactive=is_interactive, tickers_arg=args.tickers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgvoL57zXiUD",
        "outputId": "8e11e701-0e8b-44b7-9500-288b1f8185e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ‘ï¸ ILLUMINATI TERMINAL v10.0 (ORACLE) | 2025-12-15 15:32:11\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”® PREDICTED BOOMING INDUSTRIES (News Hype):\n",
            "+----------------+--------------+------------+\n",
            "| Theme          |   Hype_Score |   Mentions |\n",
            "|----------------+--------------+------------|\n",
            "| AI & Tech      |         31.3 |         52 |\n",
            "| EV & Auto      |         21.7 |         36 |\n",
            "| Banking        |         21.1 |         35 |\n",
            "| Infrastructure |         19.9 |         33 |\n",
            "| Green Energy   |          4.8 |          8 |\n",
            "+----------------+--------------+------------+\n",
            "\n",
            "âš¡ Analyzing 70 Assets...\n",
            "   -> IITL         | Target: 159.02     | Exit / Short Term  | SELL\n",
            "   -> HNDFDS       | Target: 433.87     | Exit / Short Term  | STRONG SELL\n",
            "   -> QPOWER       | Target: 496.32     | Mid Term (3-6 Mos) | BUY\n",
            "   -> MATRIMONY    | Target: 458.26     | Swing / Neutral    | HOLD\n",
            "   -> MHRIL        | Target: 257.06     | Exit / Short Term  | SELL\n",
            "   -> UNITEDPOLY   | Target: 29.94      | Mid Term (3-6 Mos) | BUY\n",
            "   -> PRUDENT      | Target: 1937.50    | Mid Term (3-6 Mos) | BUY\n",
            "   -> AUROPHARMA   | Target: 875.30     | Swing / Neutral    | HOLD\n",
            "   -> BSE          | Target: 1879.67    | Mid Term (3-6 Mos) | BUY\n",
            "   -> INDIGO       | Target: 4269.11    | Swing / Neutral    | HOLD\n",
            "   -> SIL          | Target: 15.37      | Exit / Short Term  | SELL\n",
            "   -> IDEA         | Target: 13.05      | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> JUSTDIAL     | Target: 1195.03    | Swing / Neutral    | HOLD\n",
            "   -> CIFL         | Target: 32.14      | Exit / Short Term  | STRONG SELL\n",
            "   -> DIXON        | Target: 9629.06    | Exit / Short Term  | STRONG SELL\n",
            "   -> URBANCO      | Target: 93.62      | Swing / Neutral    | HOLD\n",
            "   -> HOMEFIRST    | Target: 1110.00    | Swing / Neutral    | HOLD\n",
            "   -> ROUTE        | Target: 643.05     | Exit / Short Term  | SELL\n",
            "   -> TECHM        | Target: 1381.11    | Exit / Short Term  | STRONG SELL\n",
            "   -> ACE          | Target: 769.20     | Exit / Short Term  | SELL\n",
            "   -> STAR         | Target: 680.68     | Exit / Short Term  | SELL\n",
            "   -> FACT         | Target: 609.60     | Exit / Short Term  | SELL\n",
            "   -> ICICIPRULI   | Target: 507.95     | Mid Term (3-6 Mos) | BUY\n",
            "   -> SILVERTUC    | Target: 700.09     | Mid Term (3-6 Mos) | BUY\n",
            "   -> INOXWIND     | Target: 110.45     | Exit / Short Term  | STRONG SELL\n",
            "   -> NFL          | Target: 73.82      | Exit / Short Term  | SELL\n",
            "   -> PAR          | Target: 191.32     | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> BAJFINANCE   | Target: 885.29     | Swing / Neutral    | HOLD\n",
            "   -> MCX          | Target: 7720.00    | Mid Term (3-6 Mos) | BUY\n",
            "   -> WIPRO        | Target: 253.62     | Exit / Short Term  | SELL\n",
            "   -> ATGL         | Target: 448.98     | Exit / Short Term  | SELL\n",
            "   -> PERSISTENT   | Target: 5046.95    | Swing / Neutral    | HOLD\n",
            "   -> TITAN        | Target: 2985.70    | Mid Term (3-6 Mos) | BUY\n",
            "   -> ENERGYDEV    | Target: 39.29      | Mid Term (3-6 Mos) | BUY\n",
            "   -> PAYTM        | Target: 1506.61    | Mid Term (3-6 Mos) | BUY\n",
            "   -> INTERARCH    | Target: 2147.98    | Mid Term (3-6 Mos) | BUY\n",
            "   -> EMIL         | Target: 92.31      | Swing / Neutral    | HOLD\n",
            "   -> COUNCODOS    | Target: 4.58       | Exit / Short Term  | STRONG SELL\n",
            "   -> KMEW         | Target: 2781.94    | Swing / Neutral    | HOLD\n",
            "   -> TNPL         | Target: 125.79     | Swing / Neutral    | HOLD\n",
            "   -> DOLLAR       | Target: 259.31     | Swing / Neutral    | HOLD\n",
            "   -> UNIONBANK    | Target: 246.96     | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> INTLCONV     | Target: 75.53      | Swing / Neutral    | HOLD\n",
            "   -> HUDCO        | Target: 286.60     | Mid Term (3-6 Mos) | BUY\n",
            "   -> NEXTMEDIA    | Target: 117.89     | Swing / Neutral    | HOLD\n",
            "   -> TOTAL        | Target: 132.89     | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> SAIL         | Target: 121.67     | Exit / Short Term  | SELL\n",
            "   -> NAUKRI       | Target: 1009.33    | Exit / Short Term  | SELL\n",
            "   -> CHENNPETRO   | Target: 1485.97    | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> TIMETECHNO   | Target: 145.58     | Exit / Short Term  | SELL\n",
            "   -> TARIL        | Target: 264.51     | Exit / Short Term  | SELL\n",
            "   -> ATHERENERG   | Target: 650.99     | Mid Term (3-6 Mos) | BUY\n",
            "   -> TIPSMUSIC    | Target: 406.76     | Swing / Neutral    | HOLD\n",
            "   -> PRUDMOULI    | Target: 32.12      | Swing / Neutral    | HOLD\n",
            "   -> PVSL         | Target: 164.10     | Mid Term (3-6 Mos) | BUY\n",
            "   -> JYOTISTRUC   | Target: 9.85       | Exit / Short Term  | SELL\n",
            "   -> STEELXIND    | Target: 7.40       | Swing / Neutral    | HOLD\n",
            "   -> MARUTI       | Target: 14315.78   | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> GLOBAL       | Target: 69.23      | Mid Term (3-6 Mos) | BUY\n",
            "   -> FOCUS        | Target: 55.64      | Exit / Short Term  | SELL\n",
            "   -> SHAREINDIA   | Target: 255.77     | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> WEALTH       | Target: 741.22     | Swing / Neutral    | HOLD\n",
            "   -> HONASA       | Target: 203.80     | Swing / Neutral    | HOLD\n",
            "   -> WORTHPERI    | Target: 133.21     | Swing / Neutral    | HOLD\n",
            "   -> ASIANTILES   | Target: 61.45      | Swing / Neutral    | HOLD\n",
            "   -> BANG         | Target: 75.23      | Long Term (1-3 Yrs) | STRONG BUY\n",
            "   -> COMSYN       | Target: 137.53     | Mid Term (3-6 Mos) | BUY\n",
            "\n",
            "ğŸ¤– AI Insight: LLM Analysis Disabled....\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š STRATEGIC VERDICT\n",
            "================================================================================\n",
            "+------------+----------+----------------+---------------------+----------+------------+\n",
            "| Ticker     |    Price |   Target_Price | Horizon             |   Sharpe | Verdict    |\n",
            "|------------+----------+----------------+---------------------+----------+------------|\n",
            "| CHENNPETRO |   924.1  |        1485.97 | Long Term (1-3 Yrs) |     1.05 | STRONG BUY |\n",
            "| SHAREINDIA |   179.88 |         255.77 | Long Term (1-3 Yrs) |    -1    | STRONG BUY |\n",
            "| UNIONBANK  |   153.65 |         246.96 | Long Term (1-3 Yrs) |     0.58 | STRONG BUY |\n",
            "| TOTAL      |    77.48 |         132.89 | Long Term (1-3 Yrs) |     0.07 | STRONG BUY |\n",
            "| MARUTI     | 16415    |       14315.8  | Long Term (1-3 Yrs) |     1.65 | STRONG BUY |\n",
            "| BANG       |    48.78 |          75.23 | Long Term (1-3 Yrs) |    -0.94 | STRONG BUY |\n",
            "| IDEA       |    11.35 |          13.05 | Long Term (1-3 Yrs) |     0.79 | STRONG BUY |\n",
            "| PAR        |   101.48 |         191.32 | Long Term (1-3 Yrs) |    -1.8  | STRONG BUY |\n",
            "| MCX        | 10186    |        7720    | Mid Term (3-6 Mos)  |     1.11 | BUY        |\n",
            "| SILVERTUC  |   824.85 |         700.09 | Mid Term (3-6 Mos)  |     0.55 | BUY        |\n",
            "| COMSYN     |   142.99 |         137.53 | Mid Term (3-6 Mos)  |     1.35 | BUY        |\n",
            "| PAYTM      |  1310.1  |        1506.61 | Mid Term (3-6 Mos)  |     0.69 | BUY        |\n",
            "| PVSL       |   124.36 |         164.1  | Mid Term (3-6 Mos)  |    -0.94 | BUY        |\n",
            "| ENERGYDEV  |    19.99 |          39.29 | Mid Term (3-6 Mos)  |    -0.69 | BUY        |\n",
            "| PRUDENT    |  2690.4  |        1937.5  | Mid Term (3-6 Mos)  |    -0.09 | BUY        |\n",
            "| HUDCO      |   214.85 |         286.6  | Mid Term (3-6 Mos)  |    -0.4  | BUY        |\n",
            "| ICICIPRULI |   648.5  |         507.95 | Mid Term (3-6 Mos)  |    -0.42 | BUY        |\n",
            "| QPOWER     |   696.7  |         496.32 | Mid Term (3-6 Mos)  |     1.37 | BUY        |\n",
            "| BSE        |  2648.9  |        1879.67 | Mid Term (3-6 Mos)  |     0.78 | BUY        |\n",
            "| ATHERENERG |   685.25 |         650.99 | Mid Term (3-6 Mos)  |     2.87 | BUY        |\n",
            "+------------+----------+----------------+---------------------+----------+------------+\n",
            "\n",
            "============================================================\n",
            "ğŸ”¬ DEEP DIVE HIGHLIGHT: CHENNPETRO\n",
            "============================================================\n",
            "Current Price: â‚¹924.1  |  Target: â‚¹1485.97\n",
            "Verdict: STRONG BUY  |  Horizon: Long Term (1-3 Yrs)\n",
            "Valuation Method: DCF\n",
            "Calculated Fair Value: 1571.0\n",
            "Score Factors: ['Final Score: 100', 'Trend: UPTREND', 'Sharpe: 1.05']\n",
            "\n",
            "âœ… All Reports Saved to: output\n",
            "ğŸ“„ Full Deep Dive Analysis saved to: output/Deep_Dive_Full_1533.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "924ijY9levHZ"
      }
    }
  ]
}